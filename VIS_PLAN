amaroK VIS_PLAN  - Created: 22-11-2003

Abstract
========

In order to create a visualisation framework that is superior to anything 
popular available for Linux today we should plan amaroK's thoroughly 
before implementation. This document exists to map out our ideas and is
available for anyone to edit, please, if you have some good suggestion, or 
experience with this kind of work, add some comments! Thanks, Max Howell


Formatting
==========

The document has no regimented formatting, but do try to keep the wordwrap set
the same! Feel free to recommend formatting if the document becomes
unmanageable.

Editing
=======

Whatever goes. Please correct my spelling!


Plan
====

My inital thoughts were to make visualisations a separate process rather than
separate thread. The reasoning being, a crash in the vis won't crash amaroK,
threads can be unmanageable, *nix is good for new processes, we can use DCOP to
control the vis and presumable we just need to pass a handle to the relevant
arts server to the vis and leave it. Since the music playing bit is already a
separate process it makes sense to make the visualisation separate too! Also
this may mean that these visuals could be separate from amaroK and just depend
on KDE.

I was also thinking that this means it may be possible to not use Qt to
do rendering. There are probably better libraries for high speed graphics and if
there isn't a way to make DCOP not depend on a QApplication, then maybe we could
write something. It would be sorted if we could make something that can react to
arts sound output in general.

I was also thinking it would be neat to embed the visuals somehow into amaroK,
so as the background in the playlist perhaps (I know, this would probably not
work well due to the need to re-render all the AA text all the time, but still
the idea is neat) This is similar to Sonique on Windows if anyone has ever used
it.

If we make the visualisations not amaroK specific it may be possible to embed
visualisations into the Kicker, onto the desktop, etc.

MCOP seems to be the best way to get the audio data to the visuals. Problem with
current FFT arts implementation is it seems to be stuck at 17 bands, can we 
improve this? Do we want more than an FFT of the audio data? Would other data
be useful to visuals at all? Beat detection certainly would be a useful thing to
offer the visualisations, and it would certainly stop every visual implementing
its own detection.